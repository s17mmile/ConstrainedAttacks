Write paper while all steps are ongoing.

Write an extensive README to maybe make the code in this project retain its uselfulness.


Keras previous version: 3.9.2 (newest?)
Tensorflow previous version: 2.16.1




1. ImageNet and MNIST: Save training and testing data separately.
    --> Decide exactly which data should be augmented. 
    --> I would assume we augment the training data while leaving training data unchanged.
    --> Exception for ImageNet, as I cannot find the training data: use one of the three test sets for augmentation, one for evaluation.

--> YOU ARE HERE
Update MNIST comparison script to show target and label instead of "old label" as it's inaccurate.

PGD: variable step size?

RDSA: Decide on proper parameters for TopoDNN

Make constrainers and other useful a local import --> Helpers.constrainers or sth

Redo the "prediction success" outputs as the indexing can be wrong.
    --> Rename "success" arrays into something more appropriate (currently, it's 1 if the input is MISclassified, so 1-accuracy)
    --> Actually just get rid of the stupid success arrays. We have the labels, we can just check that in evaluation/display.

Write attack dispatcher script so I can just keep the actually launched .py file as a set of parameters followed by a single function call.

Create Histogram creator script

Apply and measure different distance metrics

Figure out at what point in the process I want to run the model on all the unchanged examples to creat confusion matrix.

Can PGD and RDSA be combined somehow?

TopoDNN: Count constituents

Introduce restrictions.
    --> For topodnn, find some shit that makes sense that isn't just Energy Conservation.
    --> Limit angular spread
    --> Introduce comparable restrictions for attacks on CIFAR-10 and ImageNet to see if their reactions are similar.
    --> Conclusion: does the same restriction applied to the same task produce comparable results?
    
Retrain Models. Evaluate Performance.

Make a nice readme.

Evaluate Performance impact caused by calculating adversaries one-by-one in a function call and not using some numpy array or tensorflow tensor fuckery to have it run several in a single function call in the context of the chosen data structure (array/tensor)...

Check comments of each attack function to make sure the details are correct.