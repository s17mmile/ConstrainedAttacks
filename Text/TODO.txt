Write evaluators:
    Write Feature and Label Histogram creator scripts
    Apply and measure different distance metrics
    Confusion Matrix (was previous classification correct vs. is perturbed classification correct) --> Fooling Ratio
    Correlation Matrix

Retraining
    --> a) Should take a model path and dataset as parameters, also a way to chunk the data for testing at different amounts of retraining.
    --> b) Should specify architecture and then train using a combination of the OG dataset and (chuunks of various sizes of) the adversarial data.
    --> Test retraining from scratch [using b)] and continued training of existing model [using a)].

Other:
Write Dataset and Model Overviews.
Check comments of each attack function to make sure the details are correct.
RDSA discussion: could we implement it without the need for precalc'd histograms? Calculate continuity, then just pick a uniformly random sample from which we pick the value (via a memmap? access might be a bitch). 

FUTURE:
    Can PGD and RDSA be combined somehow? A physics-oriented gradient-based attack that reduces correlations and retains distributions would be damn near perfect.
    (Evaluate Performance impact caused by calculating adversaries one-by-one in a function call and not using some numpy array or tensorflow tensor fuckery to have it run several in a single function call in the context of the chosen data structure (array/tensor)...)
    Reduce input and output dataset size by using smaller floats or doing some downsampling. We really do not need 64-bit color depth. Using less fine-grained data might massively speed up our overall performance too.
    Constrainers and FeasibilityProjectors should have a more flexible architecture, such as passing in a "Constrainer" class/subclass instance to allow for the passing of more/variable parameters.