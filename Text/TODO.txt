Discuss fundamental difference in how we constrain PGD and RDSA methods! RDSA uses the constrainer like a feasibilityProjector.
    --> Could it have both? In PGD, the constrainer could fix an adversary. Not so in RDSA.
    --> I will move the location of the RDSA constrainer for now. In fact, since RDSA is a sampled algorithm, it should remain feasible (as in the value ranges) BY DEFINITION!
    --> Avoid RDSA one-off overhead by saving histograms and continuity on disk?

Quality of life:
    --> Dispatcher should create output location if directory doesn't exist.

Big changes:
    --> Change each attack's functionality to return the label assigned to the adversary. Instead, pass a return_labels boolean: if it given, return both the label for the original and perturbed data. If not, only the adversary.
    --> Massive structural change: we can just apply constrainers after the data generation in the EVALUATION STEPS!!!!! We do not need to make multiple nigh-identical copies of an adversary dataset if the only step changed is in postprocessing.
    --> LMAOOOOOOOOOOOOO

Write evaluators:
    Write Feature and Label Histogram creator scripts
    Apply and measure different distance metrics
    Confusion Matrix (was previous classification correct vs. is perturbed classification correct) --> Fooling Ratio
    Correlation Matrix

Constrainer Architecture:
    --> First, Make constrainers and other useful maths stuff (e.g. linearRescale) a local import --> Helpers.constrainers or sth.
    --> Give constrainers both the original example and adversary candidate as parameters to enable more flexibility.

Build a proper constrainer for TopoDNN
    --> Read up on the physics that gets you the Energy
    --> Energy conservation. Also apply this as feasibilityProjector.
    --> Check out impact of nonexistent constituents --> if a constit is all 0 (doesn't exist), then the algorithm can't create a new one from thin air. Also apply this as feasibilityProjector.

REDO PGD using the constrainer as FeasibilityProjector instead!!!!!

Once we have full perturbed retraining data, both unconstrained/only ranged and constrained:  
    Write adaptable retrainer script    
    Retrain Models
    Evaluate Performance


Other:
Make a nice readme.
Write Dataset and Model Overviews.
Check comments of each attack function to make sure the details are correct.

FUTURE:
    Can PGD and RDSA be combined somehow? A physics-oriented gradient-based attack that reduces correlations and retains distributions would be damn near perfect.
    (Evaluate Performance impact caused by calculating adversaries one-by-one in a function call and not using some numpy array or tensorflow tensor fuckery to have it run several in a single function call in the context of the chosen data structure (array/tensor)...)
    Reduce input and output dataset size by using smaller floats or doing some downsampling. We really do not need 64-bit color depth. Using less fine-grained data might massively speed up our overall performance too.
    Constrainers and FeasibilityProjectors should have a more flexible architecture, such as passing in a "Constrainer" class/subclass instance to allow for the passing of more/variable parameters.